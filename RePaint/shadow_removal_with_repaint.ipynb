{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "186_hLMGITwg",
        "outputId": "798d65ea-26ed-4bcf-be42-8f17089ad8ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.21.6)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.12.1+cu113)\n",
            "Collecting blobfile\n",
            "  Downloading blobfile-2.0.0-py3-none-any.whl (73 kB)\n",
            "\u001b[K     |████████████████████████████████| 73 kB 764 kB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.64.1)\n",
            "Requirement already satisfied: pyYaml in /usr/local/lib/python3.7/dist-packages (6.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (7.1.2)\n",
            "Collecting mpi4py\n",
            "  Downloading mpi4py-3.1.4.tar.gz (2.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.5 MB 17.1 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (4.1.1)\n",
            "Collecting pycryptodomex~=3.8\n",
            "  Downloading pycryptodomex-3.15.0-cp35-abi3-manylinux2010_x86_64.whl (2.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 25.3 MB/s \n",
            "\u001b[?25hCollecting urllib3~=1.25\n",
            "  Downloading urllib3-1.26.13-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[K     |████████████████████████████████| 140 kB 69.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml~=4.9 in /usr/local/lib/python3.7/dist-packages (from blobfile) (4.9.1)\n",
            "Requirement already satisfied: filelock~=3.0 in /usr/local/lib/python3.7/dist-packages (from blobfile) (3.8.0)\n",
            "Building wheels for collected packages: mpi4py\n",
            "  Building wheel for mpi4py (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mpi4py: filename=mpi4py-3.1.4-cp37-cp37m-linux_x86_64.whl size=2185769 sha256=0fd8787950dcc715a5cb01ddc4e3b5313f68f80d7ef61a3da86112ef02a2a622\n",
            "  Stored in directory: /root/.cache/pip/wheels/99/54/29/187b5768bbb7beeab6753bc30acf56f35bc8ca9c214a31e173\n",
            "Successfully built mpi4py\n",
            "Installing collected packages: urllib3, pycryptodomex, mpi4py, blobfile\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "requests 2.23.0 requires urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1, but you have urllib3 1.26.13 which is incompatible.\u001b[0m\n",
            "Successfully installed blobfile-2.0.0 mpi4py-3.1.4 pycryptodomex-3.15.0 urllib3-1.26.13\n"
          ]
        }
      ],
      "source": [
        "! pip install numpy torch blobfile tqdm pyYaml pillow mpi4py"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%env CUDA_LAUNCH_BLOCKING=1\n",
        "REPAINT_PATH = \"/content/drive/MyDrive/Shadow\\ Removal\\ DDPM\\ Project/RePaint/test.py\"\n",
        "CONF_PATH = \"/content/drive/MyDrive/Shadow\\ Removal\\ DDPM\\ Project/RePaint/confs/face_example.yml\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OT7mmsJ0IhGA",
        "outputId": "e4a1517c-53e1-4694-b635-8ee944e9ceb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: CUDA_LAUNCH_BLOCKING=1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python $REPAINT_PATH --conf_path $CONF_PATH"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMzwRoA6IjfC",
        "outputId": "2f518e44-077d-4585-a52e-c72dd79d0e62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start face_example\n",
            "cosine\n",
            "4000\n",
            "---------\n",
            "[9.86581881e-06 1.01694149e-05 1.04730140e-05 ... 5.55555443e-01\n",
            " 7.49999962e-01 9.99000000e-01]\n",
            "sampling...\n",
            "100% 7168/7168 [2:38:20<00:00,  1.33s/it]\n",
            " 33% 2400/7168 [53:02<2:09:08,  1.63s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch"
      ],
      "metadata": {
        "id": "XiUnUtma9BX2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_schedule_jump(t_T, n_sample, jump_length, jump_n_sample,\n",
        "                      jump2_length=1, jump2_n_sample=1,\n",
        "                      jump3_length=1, jump3_n_sample=1,\n",
        "                      start_resampling=100000000):\n",
        "\n",
        "    jumps = {}\n",
        "    for j in range(0, t_T - jump_length, jump_length):\n",
        "        jumps[j] = jump_n_sample - 1\n",
        "\n",
        "    jumps2 = {}\n",
        "    for j in range(0, t_T - jump2_length, jump2_length):\n",
        "        jumps2[j] = jump2_n_sample - 1\n",
        "\n",
        "    jumps3 = {}\n",
        "    for j in range(0, t_T - jump3_length, jump3_length):\n",
        "        jumps3[j] = jump3_n_sample - 1\n",
        "\n",
        "    t = t_T\n",
        "    ts = []\n",
        "\n",
        "    while t >= 1:\n",
        "        t = t-1\n",
        "        ts.append(t)\n",
        "\n",
        "        if (\n",
        "            t + 1 < t_T - 1 and\n",
        "            t <= start_resampling\n",
        "        ):\n",
        "            for _ in range(n_sample - 1):\n",
        "                t = t + 1\n",
        "                ts.append(t)\n",
        "\n",
        "                if t >= 0:\n",
        "                    t = t - 1\n",
        "                    ts.append(t)\n",
        "\n",
        "        if (\n",
        "            jumps3.get(t, 0) > 0 and\n",
        "            t <= start_resampling - jump3_length\n",
        "        ):\n",
        "            jumps3[t] = jumps3[t] - 1\n",
        "            for _ in range(jump3_length):\n",
        "                t = t + 1\n",
        "                ts.append(t)\n",
        "\n",
        "        if (\n",
        "            jumps2.get(t, 0) > 0 and\n",
        "            t <= start_resampling - jump2_length\n",
        "        ):\n",
        "            jumps2[t] = jumps2[t] - 1\n",
        "            for _ in range(jump2_length):\n",
        "                t = t + 1\n",
        "                ts.append(t)\n",
        "            jumps3 = {}\n",
        "            for j in range(0, t_T - jump3_length, jump3_length):\n",
        "                jumps3[j] = jump3_n_sample - 1\n",
        "\n",
        "        if (\n",
        "            jumps.get(t, 0) > 0 and\n",
        "            t <= start_resampling - jump_length\n",
        "        ):\n",
        "            jumps[t] = jumps[t] - 1\n",
        "            for _ in range(jump_length):\n",
        "                t = t + 1\n",
        "                ts.append(t)\n",
        "            jumps2 = {}\n",
        "            for j in range(0, t_T - jump2_length, jump2_length):\n",
        "                jumps2[j] = jump2_n_sample - 1\n",
        "\n",
        "            jumps3 = {}\n",
        "            for j in range(0, t_T - jump3_length, jump3_length):\n",
        "                jumps3[j] = jump3_n_sample - 1\n",
        "\n",
        "    ts.append(-1)\n",
        "\n",
        "    return ts"
      ],
      "metadata": {
        "id": "rLEcxdUe_XQJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lpips"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oe_dpTxtjTaX",
        "outputId": "a09fbb2a-a5a8-43c8-8189-655f467c71b1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting lpips\n",
            "  Downloading lpips-0.1.4-py3-none-any.whl (53 kB)\n",
            "\u001b[?25l\r\u001b[K     |██████                          | 10 kB 22.4 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 20 kB 13.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 30 kB 10.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 40 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 51 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 53 kB 1.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from lpips) (1.7.3)\n",
            "Requirement already satisfied: torchvision>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from lpips) (0.14.0+cu116)\n",
            "Requirement already satisfied: tqdm>=4.28.1 in /usr/local/lib/python3.8/dist-packages (from lpips) (4.64.1)\n",
            "Requirement already satisfied: torch>=0.4.0 in /usr/local/lib/python3.8/dist-packages (from lpips) (1.13.0+cu116)\n",
            "Requirement already satisfied: numpy>=1.14.3 in /usr/local/lib/python3.8/dist-packages (from lpips) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=0.4.0->lpips) (4.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchvision>=0.2.1->lpips) (2.23.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision>=0.2.1->lpips) (7.1.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision>=0.2.1->lpips) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision>=0.2.1->lpips) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision>=0.2.1->lpips) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision>=0.2.1->lpips) (3.0.4)\n",
            "Installing collected packages: lpips\n",
            "Successfully installed lpips-0.1.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shadow_results = \"/content/drive/MyDrive/Shadow_Removal_DDPM_Project/ISTD_Dataset/test/test_results\"\n",
        "shadow_free = \"/content/drive/MyDrive/Shadow_Removal_DDPM_Project/ISTD_Dataset/test/test_non_shadow\"\n",
        "original_test = \"/content/drive/MyDrive/Shadow_Removal_DDPM_Project/ISTD_Dataset/test_backup/test_C\"\n",
        "resized = \"/content/drive/MyDrive/Shadow_Removal_DDPM_Project/ISTD_Dataset/test/non_shadow_resized/\"\n",
        "decay_results = \"/content/drive/MyDrive/Shadow_Removal_DDPM_Project/ISTD_Dataset/test/decay_results/\"\n",
        "decay_original = \"/content/drive/MyDrive/Shadow_Removal_DDPM_Project/ISTD_Dataset/test/decay_original/\"\n",
        "\n",
        "import cv2"
      ],
      "metadata": {
        "id": "-87pUvFpoGjW"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import lpips\n",
        "import os\n",
        "\n",
        "loss_fn = lpips.LPIPS(net='alex')\n",
        "gt = os.listdir(resized)\n",
        "res = os.listdir(shadow_results)\n",
        "\n",
        "print(len(gt))\n",
        "print(len(res))\n",
        "\n",
        "# d = loss_fn.forward(im0,im1)\n",
        "# for i in range(len(gt)):\n",
        "  # print(gt[i], res[i])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ubMmBd3jUM9",
        "outputId": "dbfd4a45-1a76-49db-e413-0f3b56df9b68"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n",
            "51\n",
            "51\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# shadow_results_files = os.listdir(shadow_results)\n",
        "# for i in range(len(shadow_results_files)):\n",
        "#   # print(shadow_results_files[i])\n",
        "#   img = cv2.imread(os.path.join(original_test,shadow_results_files[i]))\n",
        "#   img_resize = cv2.resize(img, (256,256))\n",
        "#   print(os.path.join(resized, shadow_results_files[i]))\n",
        "#   # cv2.imwrite(os.path.join(resized, shadow_results_files[i]), img_resize)\n",
        "#   # print(img.shape)\n"
      ],
      "metadata": {
        "id": "AKpkuhatpxBL"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import lpips\n",
        "from IPython import embed\n",
        "\n",
        "use_gpu = False         # Whether to use GPU\n",
        "spatial = True         # Return a spatial map of perceptual distance.\n",
        "\n",
        "# Linearly calibrated models (LPIPS)\n",
        "loss_fn = lpips.LPIPS(net='alex', spatial=spatial) # Can also set net = 'squeeze' or 'vgg'\n",
        "# loss_fn = lpips.LPIPS(net='alex', spatial=spatial, lpips=False) # Can also set net = 'squeeze' or 'vgg'\n",
        "\n",
        "if(use_gpu):\n",
        "\tloss_fn.cuda()\n",
        "\n",
        "## Example usage with dummy tensors\n",
        "# dummy_im0 = torch.zeros(1,3,64,64) # image should be RGB, normalized to [-1,1]\n",
        "# dummy_im1 = torch.zeros(1,3,64,64)\n",
        "# if(use_gpu):\n",
        "# \tdummy_im0 = dummy_im0.cuda()\n",
        "# \tdummy_im1 = dummy_im1.cuda()\n",
        "# dist = loss_fn.forward(dummy_im0,dummy_im1)\n",
        "\n",
        "## Example usage with images\n",
        "distance = []\n",
        "for i in range(len(gt)):\n",
        "\n",
        "  ex_ref = lpips.im2tensor(lpips.load_image(os.path.join(resized, gt[i])))\n",
        "  ex_p0 = lpips.im2tensor(lpips.load_image(os.path.join(shadow_results, gt[i])))\n",
        "  # ex_p1 = lpips.im2tensor(lpips.load_image('./imgs/ex_p1.png'))\n",
        "  if(use_gpu):\n",
        "    ex_ref = ex_ref.cuda()\n",
        "    ex_p0 = ex_p0.cuda()\n",
        "    # ex_p1 = ex_p1.cuda()\n",
        "\n",
        "  ex_d0 = loss_fn.forward(ex_ref,ex_p0)\n",
        "  # ex_d1 = loss_fn.forward(ex_ref,ex_p1)\n",
        "\n",
        "  if not spatial:\n",
        "      print('Distances: (%.3f)'%(ex_d0))\n",
        "      distance.append(ex_d0)\n",
        "  else:\n",
        "      print('Distances: (%.3f)'%(ex_d0.mean()))            # The mean distance is approximately the same as the non-spatial distance\n",
        "      distance.append(ex_d0.mean())\n",
        "      # Visualize a spatially-varying distance map between ex_p0 and ex_ref\n",
        "      # import pylab\n",
        "      # pylab.imshow(ex_d0[0,0,...].data.cpu().numpy())\n",
        "      # pylab.show()\n",
        "\n",
        "print(\"LPIPS : \", sum(distance)/len(distance))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oND-evXutyy6",
        "outputId": "13d3679b-6574-4a64-8d7c-5c68d9f6622f"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [on]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n",
            "Distances: (0.315)\n",
            "Distances: (0.356)\n",
            "Distances: (0.415)\n",
            "Distances: (0.329)\n",
            "Distances: (0.308)\n",
            "Distances: (0.479)\n",
            "Distances: (0.356)\n",
            "Distances: (0.302)\n",
            "Distances: (0.418)\n",
            "Distances: (0.432)\n",
            "Distances: (0.289)\n",
            "Distances: (0.357)\n",
            "Distances: (0.493)\n",
            "Distances: (0.281)\n",
            "Distances: (0.287)\n",
            "Distances: (0.491)\n",
            "Distances: (0.281)\n",
            "Distances: (0.223)\n",
            "Distances: (0.319)\n",
            "Distances: (0.303)\n",
            "Distances: (0.279)\n",
            "Distances: (0.468)\n",
            "Distances: (0.309)\n",
            "Distances: (0.203)\n",
            "Distances: (0.464)\n",
            "Distances: (0.148)\n",
            "Distances: (0.365)\n",
            "Distances: (0.423)\n",
            "Distances: (0.351)\n",
            "Distances: (0.257)\n",
            "Distances: (0.302)\n",
            "Distances: (0.266)\n",
            "Distances: (0.240)\n",
            "Distances: (0.271)\n",
            "Distances: (0.289)\n",
            "Distances: (0.247)\n",
            "Distances: (0.293)\n",
            "Distances: (0.245)\n",
            "Distances: (0.332)\n",
            "Distances: (0.387)\n",
            "Distances: (0.331)\n",
            "Distances: (0.265)\n",
            "Distances: (0.190)\n",
            "Distances: (0.188)\n",
            "Distances: (0.413)\n",
            "Distances: (0.238)\n",
            "Distances: (0.350)\n",
            "Distances: (0.278)\n",
            "Distances: (0.198)\n",
            "Distances: (0.252)\n",
            "Distances: (0.740)\n",
            "LPIPS :  tensor(0.3258, grad_fn=<DivBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decay_results_files = os.listdir(decay_results)\n",
        "decay_original_files = os.listdir(decay_original)\n",
        "for i in range(len(decay_results_files)):\n",
        "  # print(decay_results_files[i])\n",
        "  # img = cv2.imread(os.path.join(original_test,decay_results_files[i]))\n",
        "  # print(img.shape)\n",
        "  # img_resize = cv2.resize(img, (256,256))\n",
        "  # print(os.path.join(decay_original, decay_results_files[i]))\n",
        "  # cv2.imwrite(os.path.join(decay_original, decay_results_files[i]), img_resize)\n",
        "  # print(img.shape)\n",
        "  print(decay_results_files[i], decay_original_files[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQPVXw0yzouk",
        "outputId": "7648a536-d7a8-44a7-f12e-4a825ec1a5ae"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "121-3.png 121-3.png\n",
            "109-11.png 109-11.png\n",
            "115-5.png 115-5.png\n",
            "117-17.png 117-17.png\n",
            "117-5.png 117-5.png\n",
            "112-4.png 112-4.png\n",
            "114-10.png 114-10.png\n",
            "108-10.png 108-10.png\n",
            "124-2.png 124-2.png\n",
            "93-3.png 93-3.png\n",
            "105-19.png 105-19.png\n",
            "104-1.png 104-1.png\n",
            "101-4.png 101-4.png\n",
            "91-10.png 91-10.png\n",
            "91-4.png 91-4.png\n",
            "120-7.png 120-7.png\n",
            "96-1.png 96-1.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import lpips\n",
        "from IPython import embed\n",
        "\n",
        "use_gpu = False         # Whether to use GPU\n",
        "spatial = True         # Return a spatial map of perceptual distance.\n",
        "\n",
        "# Linearly calibrated models (LPIPS)\n",
        "loss_fn = lpips.LPIPS(net='alex', spatial=spatial) # Can also set net = 'squeeze' or 'vgg'\n",
        "# loss_fn = lpips.LPIPS(net='alex', spatial=spatial, lpips=False) # Can also set net = 'squeeze' or 'vgg'\n",
        "\n",
        "if(use_gpu):\n",
        "\tloss_fn.cuda()\n",
        "\n",
        "## Example usage with dummy tensors\n",
        "# dummy_im0 = torch.zeros(1,3,64,64) # image should be RGB, normalized to [-1,1]\n",
        "# dummy_im1 = torch.zeros(1,3,64,64)\n",
        "# if(use_gpu):\n",
        "# \tdummy_im0 = dummy_im0.cuda()\n",
        "# \tdummy_im1 = dummy_im1.cuda()\n",
        "# dist = loss_fn.forward(dummy_im0,dummy_im1)\n",
        "\n",
        "## Example usage with images\n",
        "distance = []\n",
        "for i in range(len(decay_results_files)):\n",
        "\n",
        "  ex_ref = lpips.im2tensor(lpips.load_image(os.path.join(decay_results, decay_results_files[i])))\n",
        "  ex_p0 = lpips.im2tensor(lpips.load_image(os.path.join(decay_original, decay_results_files[i])))\n",
        "  # ex_p1 = lpips.im2tensor(lpips.load_image('./imgs/ex_p1.png'))\n",
        "  if(use_gpu):\n",
        "    ex_ref = ex_ref.cuda()\n",
        "    ex_p0 = ex_p0.cuda()\n",
        "    # ex_p1 = ex_p1.cuda()\n",
        "\n",
        "  ex_d0 = loss_fn.forward(ex_ref,ex_p0)\n",
        "  # ex_d1 = loss_fn.forward(ex_ref,ex_p1)\n",
        "\n",
        "  if not spatial:\n",
        "      print('Distances: (%.3f)'%(ex_d0))\n",
        "      distance.append(ex_d0)\n",
        "  else:\n",
        "      print('Distances: (%.3f)'%(ex_d0.mean()))            # The mean distance is approximately the same as the non-spatial distance\n",
        "      distance.append(ex_d0.mean())\n",
        "      # Visualize a spatially-varying distance map between ex_p0 and ex_ref\n",
        "      # import pylab\n",
        "      # pylab.imshow(ex_d0[0,0,...].data.cpu().numpy())\n",
        "      # pylab.show()\n",
        "\n",
        "print(\"LPIPS : \", sum(distance)/len(distance))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whvU8_t72eoh",
        "outputId": "8e3a2f29-97ac-410b-e382-ea623f14d07a"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [on]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n",
            "Distances: (0.464)\n",
            "Distances: (0.225)\n",
            "Distances: (0.309)\n",
            "Distances: (0.281)\n",
            "Distances: (0.466)\n",
            "Distances: (0.307)\n",
            "Distances: (0.351)\n",
            "Distances: (0.276)\n",
            "Distances: (0.261)\n",
            "Distances: (0.288)\n",
            "Distances: (0.201)\n",
            "Distances: (0.283)\n",
            "Distances: (0.254)\n",
            "Distances: (0.279)\n",
            "Distances: (0.363)\n",
            "Distances: (0.504)\n",
            "Distances: (0.149)\n",
            "LPIPS :  tensor(0.3094, grad_fn=<DivBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6W5jIput4oRy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}